<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
h1 {
	text-align: center;
}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
			<div style="text-align: center;">Names: </div>

			<br>

			Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-z_hello_world/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-z_hello_world/hw3/index.html</a>
			<br>
			Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw-webpages-z_hello_world">https://github.com/cal-cs184-student/hw-webpages-z_hello_world</a>

			<figure>
				<img src="cover.png" alt="" style="width:20%"/>
			</figure>

			<!--
				We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
			-->

			<h2>Overview</h2>
			In this homework, I implemented the path tracing algorithm along with some necessary optimizations to make it practical. These included a traversal acceleration structure, importance sampling, and adaptive sampling.
			It is able to create very realistic renders of simple diffuse scenes. I learned a lot about how path tracing and practical global illumination work. Thinking of it as a sum of number of bounces is very interesting.

			<h2>Part 1: Ray Generation and Scene Intersection</h2>
			<ul>
				<li>
					The ray generation starts with a position on the screen (\(p\in[0,1]\times[0,1]\)) and returns the corresponding camera ray in world space. It does this by evaluating the following formula:
					\[\vec{o_r} = \text{camera position}\]
					\[\vec{d_r} = \text{normalize}\left(\begin{bmatrix}
					(2x_p-1)\tan\left(\frac{h_{fov}}{2}\right)\\
					(2y_p-1)\tan\left(\frac{v_{fov}}{2}\right)\\
					-1\end{bmatrix}
					\right)\]
					The ray points in the negative \(Z\) direction to follow the right hand rule when writing the axis \((x,y,z)\).<br>
					The tangent function gives the ratio of depth to perpendicular distance (at an angle). This is perfect when trying to find the ray's horizontal and vertical directions at depth \(1\).
				</li>
				<li>
					I implemented the Möller Trumbore algorithm. The algorithm finds the intersection point in terms of barycentric coordinates and the depth.
					This is nice because it finds the barycentric coordinates directly rather than having to compute them after finding the intersection in world space.
					<br>
					It does this by solving:
					\[t\cdot\vec{d_r} + \vec{o_r} = u\cdot\vec{P_1} + v\cdot\vec{P_2} + w\cdot\vec{P_3}\]
					where \(u, v, w\) are the barycentric coordinates.
					<br>
					Substituting \(u\) with \(1-v-w\) yields a system of 3 equations with 3 unknowns. The algorithm uses Cramer's rule along with some simplifications to solve the system.
					<br>
					Optimizations:<br>
					<ul>
						<li>
							I also decided to avoid dividing by the determinant until necessary. This meant checking if \(u+v>\text{det}\) rather than \(u+v>1\). (It also checks the sign of the determinant for the faster check)
							<br>
							The benefit would be that some early exits could occur and never have to divide.
						</li>
						<li>
							Early exits:<br>
							If the determinant is zero, the ray is co-planar with the triangle.<br>
							If \(v\) is out of range.<br>
							If \(w\) or \(v+w\) are out of range.<br>
							If \(t\) is out of range.
						</li>
					</ul>
				</li>
			</ul>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part1/spheres.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part1/gems.png" width="400px"/>
							<figcaption><code>sky/CBgems.dae</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part1/coil.png" width="400px"/>
							<figcaption><code>sky/CBcoil.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part1/dragon.png" width="400px"/>
							<figcaption><code>sky/CBdragon.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 2: Bounding Volume Hierarchy</h2>
			<ul>
				<li>
					The splitting algorithm starts by iterating through the three base axes.
					<br>
					For each of the axis it finds the position of the median bounding box centroid of the primitives. Then it finds the surface area of each child volume and sums them.
					<br>
					The axis split that yields the best surface area is kept.
					<br>
					Using the median element is nice because it maintains a balanced tree. It, however, cannot account for some situations that could greatly reduce the surface area. (Like if the geometry is in two tightly packed differently sized regions)
				</li>
				<li>
					Traversal Optimization:<br>
					When traversing the acceleration structure, I tried to minimize unnecessary work. To do this, the algorithm always traverses the closer child node first.
					Then it does not traverse the other child node if the ray's hit point is closer than the external hit point of the child node.
				</li>
				<li>
					Performance difference:
					<ul>
						<li>
							<code>meshedit/cow.dae</code> at 1spp, res=380x560:<br>
							Render time: 3.0241s → 0.0173s (0.57%)<br>
							BVH generation time: 0.0060s<br>
						</li>
						<li>
							<code>meshedit/maxplanck.dae</code> at 1spp, res=380x560:<br>
							Render time: 25.3723s → 0.0231s (0.091%)<br>
							BVH generation time: 0.0760s<br>
						</li>
						<li>
							<code>sky/CBlucy.dae</code> at 1spp, res=380x560:<br>
							Render time: 84.5542s → 0.0157s (0.018%)<br>
							BVH generation time: 0.2362s<br>
						</li>
					</ul>
					This is quite a large speedup. Even when considering the generation time of the BVH. If the BVH had to be re-constructed every render, it would still be very worth while.
					<br>
					Going from least to most triangles, the performance improvement clearly increases. The cow took 0.57% of the original time while the angel took 0.018% of the time.
					This makes sense because the naive method increases linearly while the BVH traversal increases inverse exponentially.
				</li>
			</ul>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part2/lucy.png" width="400px"/>
							<figcaption><code>sky/CBlucy.dae</code> (64 spp)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part2/wall-e.png" width="400px"/>
							<figcaption><code>sky/wall-e.dae</code> (64 spp)</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part2/maxplanck.png" width="400px"/>
							<figcaption><code>meshedit/maxplanck.dae</code> (64 spp)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part2/bvh.png" width="400px"/>
							<figcaption>BVH visualization for <code>sky/wall-e.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 3: Direct Illumination</h2>
			<ul>
				<li>
					Both of the direct lighting functions start by getting relevant information about the intersection. (hit point, incoming direction, space conversion matrices).
					<br>
					Then they accumulate samples.
					<ul>
						<li>
							The uniform sampler samples by the number of lights times the number of samples per light.
							<br>
							For each, it gets a random direction from the surface. It converts it to world space and emits a ray in that direction.
							<br>
							If the ray hits something, it adds the BSDF times the emission of the object it hit and accumulates the result.
							<br>
							Then it divides the final accumulation by the number of samples and appropriate constant(s) (pdf=\(\frac{1}{2}\)).
						</li>
						<li>
							The importance sampler iterates through the lights. Point lights only get sampled once, while area lights get sampled according to the command line argument.
							<br>
							Then it accumulates (for each sample that hit) the BSDF times the radiance over the pdf.
							<br>
							The accumulation for each light is divided by the number of samples spent on that light, then added to a larger accumulator.
							<br>
							Then the final accumulation of all lights is divided by appropriate constant(s) (\(\pi\)).
						</li>
					</ul>
				</li>
				<li>
					Optimization:<br>
					To save some (very small) amount of work, I delayed dividing by the probability density function until the end (when it was constant).<br>
					I'm not sure if the compiler would have optimized this on its own because it has slightly different behavior (due to finite precision).
				</li>
				<li>
					The importance sampling improves results greatly. The uniformly sampled images are extremely noisy everywhere while the importance sampled images are primarily just noisy in partially shadowed areas.
					<br>
					This follows intuitive expectation because the chance that a uniform sample hits a light is low, but when it does hit, the effect is high.
				</li>
				<li>
					It appears that the effect of more samples (when importance sampling) diminishes. The difference between 1 sample and 4 samples appears larger than the difference between 16 samples and 64 samples.
					This (most likely) means that it is converging because as it converges, the effect of refinement becomes less and less.
				</li>
			</ul>

			<p>Comparison of uniform hemisphere sampling (left) and importance sampling (right) at 32 light samples:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_unif.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>uniform</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/bunny_unif.png" width="400px"/>
							<figcaption><code>sky/CBbunny.dae</code><br>uniform</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/bunny_imp.png" width="400px"/>
							<figcaption><code>sky/CBbunny.dae</code><br>importance</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Importance sampling at different light sample rates:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_1x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 1 light sample</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_4x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 4 light samples</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_16x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 16 light samples</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_64x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 64 light samples</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 4: Global Illumination</h2>
			<ul>
				<li>
					My implementation of the lighting function was a little different than the recursive description given in class. I unrolled the recursion and accumulated values.
					<br>
					\(R_n\) being the one bounce radiance:
					\[L_1 = R_1 + \frac{f_1}{p_1}L_2, L_n = R_n + \frac{f_n}{p_n}L_{n+1}\]
					\[L_1 = R_1 + \frac{f_1}{p_1}\left( R_2 + \frac{f_2}{p_2}\left( R_3 + \frac{f_3}{p_3}\left( R_4 + \frac{f_4}{p_4}\left( R_5 + \frac{f_5}{p_5}\left( \cdots \right) \right) \right) \right) \right)\]
					Because the recursive algorithm always terminates in a finite amount of time (\(\exists N, L_N:=0\)):
					\[L_1 = R_1 + \sum_{n=1}^{N}{ R_{i+1} \prod_{i=1}^{n-1} { \frac{f_i}{p_i} } }\]
					So now this can be written in a for loop that accumulates \(f\) and \(p\). Because \(f\) is a vector and \(p\) is a scalar, it made sense to have two different variables for accumulating them.
					<br>
					The final for loop does the following:<br>
					<ul>
						<li>Check for intersection, if miss, break.</li>
						<li>Add zero bounce radiance if this is the first ray.</li>
						<li>Calculate space conversion matrices.</li>
						<li>Add the product of the one bounce radiance and the accumulated values to the total light value.</li>
						<li>Create the next ray based on a new BSDF sample.</li>
						<li>Accumulate \(f\) and \(p\) (<code>pdf</code>) from the new BSDF sample.</li>
					</ul>
					<br>
					This method was chosen to reduce stack allocations and memory usage. The memory usage is constant with path depth. This optimization is likely necessary when implementing this on graphics hardware.
				</li>
			</ul>

			<p>Global illumination for a few scenes:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/global/spheres.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/global/dragon.png" width="370px"/>
							<figcaption><code>sky/dragon.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/global/bench.png" width="370px"/>
							<figcaption><code>sky/bench.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			In the following scene, the lighting is able to reach most of the model, so the effect of indirect illumination is fairly subtle.
			Looking at the indirect illumination only, the model appears to be lit from below. This makes sense because the light is going from above, reflecting off the upwards facing surfaces and hitting the downwards facing surfaces.
			<p>Comparison of only direct and only indirect illumination for <code>sky/wall-e.dae</code>:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/full.png" width="370px"/>
							<figcaption>global (sum)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/direct.png" width="370px"/>
							<figcaption>direct only</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/indirect.png" width="370px"/>
							<figcaption>indirect only</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			For the following image comparison:<br>
			The second and third bounces appear to get almost of the indirect lighting in this scene. The second bounce seems to capture all of the light reflected directly off of the floor.
			This is a fairly large effect because the light is facing the floor (so a lot of energy is going there).
			The second bounce also shows how the colors of the walls appear on the floor and ceiling.
			The third bounce appears to be adding some of the same effects but attenuated.
			Both are also adding light in areas that have a large open/visible surface area which ends up creating the effect of ambient occlusion.
			Rasterization rendering would usually create the ambient and ambient occlusion lighting in a very limited and approximate way. It would not create the color bleeding at all.

			<p>Global illumination breakdown for <code>sky/CBbunny.dae</code>:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_0.png" width="190px"/>
							<figcaption>0 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_1.png" width="190px"/>
							<figcaption>1 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_2.png" width="190px"/>
							<figcaption>2 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_3.png" width="190px"/>
							<figcaption>3 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_4.png" width="190px"/>
							<figcaption>4 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_5.png" width="190px"/>
							<figcaption>5 Bounce</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_0.png" width="190px"/>
							<figcaption>0 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_1.png" width="190px"/>
							<figcaption>1 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_2.png" width="190px"/>
							<figcaption>2 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_3.png" width="190px"/>
							<figcaption>3 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_4.png" width="190px"/>
							<figcaption>4 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_5.png" width="190px"/>
							<figcaption>5 Bounce</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Comparison of different maximum ray depths for <code>sky/CBbunny.dae</code> (Russian Roulette factor 0.3):</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/depth/0.png" width="370px"/>
							<figcaption>0</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/1.png" width="370px"/>
							<figcaption>1</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/2.png" width="370px"/>
							<figcaption>2</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/depth/3.png" width="370px"/>
							<figcaption>3</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/4.png" width="370px"/>
							<figcaption>4</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/100.png" width="370px"/>
							<figcaption>100</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Comparison of different sample per pixel rates for <code>sky/CBspheres_lambertian.dae</code> (at 4 light samples):</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/1.png" width="280px"/>
							<figcaption>1</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/2.png" width="280px"/>
							<figcaption>2</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/4.png" width="280px"/>
							<figcaption>4</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/8.png" width="280px"/>
							<figcaption>8</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/16.png" width="280px"/>
							<figcaption>16</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/32.png" width="280px"/>
							<figcaption>32</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/64.png" width="280px"/>
							<figcaption>64</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/1024.png" width="280px"/>
							<figcaption>1024</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 5: Adaptive Sampling</h2>
			<ul>
				<li>
					To implement the adaptive sampling, I just modified the existing loop to check a condition every <code>samplesPerBatch</code> iterations.
					<br>
					Every iteration also sums the illumination and square of the illumination.
					<br>
					Then every <code>samplesPerBatch</code> samples, it calculates \(I\) and \(\mu\) to determine if the pixel has converged. If the pixel converged, it breaks out of the loop.
					<br>
					The only issue was that in some lighting conditions, some samples would converge too early. This primarily only happened to indirect lighting.
					To fix this, I only start checking the convergence of samples after <code>4*samplesPerBatch</code> samples. This way there is a greatly reduced chance of a pixel only sampling too many zeros and returning early.
				</li>
			</ul>

			<p>Adaptive sampling:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part5/spheres.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part5/spheres_rate.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part5/wall-e.png" width="370px"/>
							<figcaption><code>sky/wall-e.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part5/wall-e_rate.png" width="370px"/>
							<figcaption><code>sky/wall-e.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
			<h3>GPU Compute</h3>
			<h4>Restructuring:</h4>

			In order to implement this, I started by restructuring some code to allow for selecting the GPU or CPU to do rendering with a command line argument.<br>
			I made a new class, <code>GPUPathTracer</code>, which renders the entire image using the GPU.<br>
			I made another new class, <code>GPU_BVHAccel</code>, which is a version of the BVH that it optimized for sending to and using on the GPU.<br>
			Because (at least the last I heard) OpenGL does not support multithreading, I completely disable any thread spawning when GPU compute is selected.

			<h4>Ray Generation:</h4>

			To compute rays from the camera, I opted to use a matrix. This was because the entire view transformation could be done with two mutliplications using this matrix. (and 6 divisions, 3 subtractions, and a vector normalization to get the final ray).
			<br>
			The goal is for ray perspective generation and the camera transformation to be done simultaneously.
			<br>
			The final matrix looked like this (should look similar to the inverse of the standard perspective matrix):
			\[
			M=\begin{bmatrix}
			\frac{2}{\text{width}}\cdot\tan\left(\frac{f_h}{2}\right) && 0 && 0 && -\tan\left(\frac{f_h}{2}\right)\\
			0 && \frac{2}{\text{height}}\cdot\tan\left(\frac{f_v}{2}\right) && 0 && -\tan\left(\frac{f_v}{2}\right)\\
			0 && 0 && 0 && -1\\
			0 && 0 && -\frac{\text{far}-\text{near}}{\text{far}\cdot\text{near}} && \frac{\text{far}}{\text{far}\cdot\text{near}}
			\end{bmatrix}
			\]
			Taking the vectors,
			\[
			\alpha=\begin{bmatrix}
			x\\y\\0\\1
			\end{bmatrix}
			,
			\beta=\begin{bmatrix}
			x\\y\\1\\1
			\end{bmatrix}
			\]
			and computing,
			\[
			a=\frac{(M\alpha)_{xyz}}{(M\alpha)_w}, b=\frac{(M\beta)_{xyz}}{(M\beta)_w}
			\]
			yields the ray origin and direction,
			\[
			r_o = a\\
			r_d = \text{normalize}(b-a)
			\]
			What this is doing is finding coordinates on the near and far planes. The origin is set to the coordinate on the near plane, and the direction is the difference between the point on the near and far planes.
			<br>
			Consequently, the ray starts at the near plane rather than the pinhole camera's origin. This means that the ray's minimum \(t\) should be set to zero for the camera ray.
			<br>
			The benifit is that this matrix can be combined with the camera view matrix, and the latter computation can be done afterwards. (leaving just one 4x4 matrix being sent to the GPU program)
			<br>
			This also handles the pixel location directly (rather than having to scale to \([0,1]\)coordinates first).
			<br>
			Testing:
			<br>
			<p>Testing the ray origin:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_x.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera to the right.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_y.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera up.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_z.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera back.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<p>Testing the ray direction:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/ray_dir_test.png" width="370px"/>
							<figcaption>The direction of the ray for each pixel after rotating the camera slightly up and to the right.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			Actual triangle intersections will be much more conclusive as to whether this is working propertly or not. If the scene aligns perfectly, then it is likely correct.

			<h4>Triangle Intersection:</h4>

			I used an OpenGL storage buffer to send the data for each triangle.<br>
			I translated the earlier implementation of the Möller Trumbore algorithm in GLSL.<br>
			<br>
			A compute shader does the actual computation using a for loop to go through each triangle.

			<p>Testing the ray generation and triangle intersection:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/normal_shading.png" width="370px"/>
							<figcaption><code>sky/CBempty.dae</code> with raw absolute value normal shading.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/bunny_normal.png" width="370px"/>
							<figcaption><code>sky/CBbunny.dae</code> with raw absolute value normal shading.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			The bunny only took 8.3613 seconds with no acceleration structure, so despite having to check a huge number of triangle intersections, it is relatively fast.
			<br>
			Also, these results show that the ray generation from the previous part is working. The position of the faces do not change at all when rendering.

			<p>Testing the near clipping plane with the ray generation:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/near_clipping.png" width="370px"/>
							<figcaption><code>sky/CBempty.dae</code> very close to camera</figcaption>
						</td>
					</tr>
				</table>
			</div>

			The clipping effect in this image aligned with the clipping done by the rasterized preview, so it is likely correct.

			<h4>Acceleration Structure Construction, Storage, and Traversal:</h4>

			The structure of the BVH I implemented in GPU memory is the following:<br>
			There is an array of triangle objects which each store 3 points and 3 normals (materials will be added to this later).<br>
			Then there is an array of nodes which store a bounding box some additional information.<br>
			Each node has four integers, two of which store the start and end indices (to be used like iterators) into the triangle array. If it is not a leaf node, they are both zero.<br>
			The other two are used for traversal (described later).
			I made it such that the root node is the first node in the array for simplicity.<br>


			<br>
			To check if any of this is working, I limited the triangles that would be checked. They appeared to be split rectangularly as I expected.
			<p>Verifying the BVH construction of the triangle array:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/bvh/triangle_array_verify.png" width="370px"/>
							<figcaption><code>sky/CBbunny.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			Recursion in GLSL is not possible, so tree traversal is made more difficult. At first I thought I would store the children and parent for each node. This might allow the shader to walk through the tree in a simple loop.<br>
			Since I haven't implemented this, I'm not sure this is possible without some sort of tree depth-sized extra memory per thread.<br>
			Instead, I came across a solution online that makes the shader very simple. For each node, you store the next node on hit and the next node on miss.
			(<a href="https://stackoverflow.com/questions/55479683/traversal-of-bounding-volume-hierachy-in-shaders">Idea from Stack Overflow</a>)<br>
			The node storage isn't any larger because child and parent pointers no longer have to be stored.<br>

			<p>Traversal:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/bvh/traversal.png" width="75%"/>
							<figcaption>Diagram displaying tree traversal</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Result:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/bvh/bunny.png" width="512px"/>
							<figcaption><code>sky/CBbunny.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/bvh/lucy.png" width="512px"/>
							<figcaption><code>sky/CBlucy.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			For the following: [__, __] CPU timing means [time for single thread, time for 20 threads (10 cores)].<br>
			<code>sky/CBlucy.dae</code> went from [0.1177, 0.0215] seconds (CPU) to 0.0126 seconds (GPU).<br>
			<code>sky/CBbunny.dae</code> went from [0.0983, 0.0209] seconds (CPU) to 0.0154 seconds (GPU).<br>
			This is not what I was hoping, but I have not done any work load optimization for the compute shader dispatch.<br>
			The GPU times also include shader compilation, resource construction, and upload time, though these are probably minimal.


			<h4>Sampling:</h4>
			Pretty much the entire random number generation is based on <code>HybridTaus</code> from <a href="https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-37-efficient-random-number-generation-and-application">GPU Gems 3 Chapter 37</a>.<br>

			It took some fiddling with the four integers used to seed the generator, but the final result looks random enough if a few time steps are used to initialize it.

			<p>Testing noise:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/grayscale_randf.png" width="370px"/>
							<figcaption>One random value between 0 and 1 for each pixel</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/rgb_randf.png" width="370px"/>
							<figcaption>Three random values between 0 and 1 for each pixel</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Sampling pixels randomly for anti-aliasing:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/bunny_ns_aa_64.png" width="512px"/>
							<figcaption><code>sky/CBbunny.dae</code> at 64spp</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/lucy_ns_aa_64.png" width="512px"/>
							<figcaption><code>sky/CBlucy.dae</code> at 64spp</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			And after a bit of code translation from other parts of the project, and copying the code for color conversion (taken from <code>HDRImageBuffer</code>):

			<p>Importance sampled area light:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/bunny_importance_cpu.png" width="512px"/>
							<figcaption>Original CPU rendering of <code>sky/CBbunny.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/sampling/bunny_importance_gpu.png" width="512px"/>
							<figcaption>New GPU rendering of <code>sky/CBbunny.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>
			<br>

			<h4>Global Illumination (final result):</h4>

			After moving the rest of the code over, here is a side by side comparisons of a globally illuminated render:
			<br>
			<br>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/global/cpu_bunny.png" width="512px"/>
							<figcaption>Original CPU rendering of <code>sky/CBbunny.dae</code><br>(single thread: 73.6548s, 20 thread: 14.5832s)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/global/gpu_bunny.png" width="512px"/>
							<figcaption>New GPU rendering of <code>sky/CBbunny.dae</code><br>(3.4601s)</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			It would appear that doing the global illumination has improved the GPU's relative performance for this specific scene.
			<br>
			<br>
			<br>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/global/lucy.png" width="512px"/>
							<figcaption>GPU rendering of <code>sky/CBlucy.dae</code> (8.2428s)</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<br><br>

			<h4>Conclusion:</h4>
			The GPU clearly makes path tracing faster for these scenes, but not as much as I expected. Especially because (for my implementation) the GPU is only working with single precision floating point numbers while the CPU is working with doubles.<br>
			I think more time (that I do not have at the moment) needs to be put into analyzing the GPU performance. I did not focus on work dispatch at all, so that would be a good place to start. Currently, it dispatches one compute thread per pixel that runs everything.

			<br><br>
		</div>
	</body>
</html>
