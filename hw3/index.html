<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
h1 {
	text-align: center;
}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
			<div style="text-align: center;">Names: </div>

			<br>

			Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-z_hello_world/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-z_hello_world/hw2/index.html</a>
			<br>
			Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw-webpages-z_hello_world">https://github.com/cal-cs184-student/hw-webpages-z_hello_world</a>

			<figure>
				<img src="cover.png" alt="" style="width:20%"/>
			</figure>

			<!--
				We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
			-->

			<h2>Overview</h2>
			In this homework, I implemented the path tracing algorithm along with some necessary optimizations to make it practical. These included a traversal acceleration structure, importance sampling, and adaptive sampling.
			It is able to create very realistic renders of simple diffuse scenes. I learned a lot about how path tracing and practical global illumination work. Thinking of it as a sum of number of bounces is very interesting.

			<h2>Part 1: Ray Generation and Scene Intersection</h2>
			<ul>
				<li>
					The ray generation starts with a position on the screen (\(p\in[0,1]\times[0,1]\)) and returns the corresponding camera ray in world space. It does this by evaluating the following formula:
					\[\vec{o_r} = \text{camera position}\]
					\[\vec{d_r} = \text{normalize}\left(\begin{bmatrix}
					(2x_p-1)\tan\left(\frac{h_{fov}}{2}\right)\\
					(2y_p-1)\tan\left(\frac{v_{fov}}{2}\right)\\
					-1\end{bmatrix}
					\right)\]
					The ray points in the negative \(Z\) direction to follow the right hand rule when writing the axis \((x,y,z)\).<br>
					The tangent function gives the ratio of depth to perpendicular distance (at an angle). This is perfect when trying to find the ray's horizontal and vertical directions at depth \(1\).
				</li>
				<li>
					I implemented the Möller Trumbore algorithm. The algorithm finds the intersection point in terms of barycentric coordinates and the depth.
					This is nice because it finds the barycentric coordinates directly rather than having to compute them after finding the intersection in world space.
					<br>
					It does this by solving:
					\[t\cdot\vec{d_r} + \vec{o_r} = u\cdot\vec{P_1} + v\cdot\vec{P_2} + w\cdot\vec{P_3}\]
					where \(u, v, w\) are the barycentric coordinates.
					<br>
					Substituting \(u\) with \(1-v-w\) yields a system of 3 equations with 3 unknowns. The algorithm uses Cramer's rule along with some simplifications to solve the system.
					<br>
					Optimizations:<br>
					<ul>
						<li>
							I also decided to avoid dividing by the determinant until necessary. This meant checking if \(u+v>\text{det}\) rather than \(u+v>1\). (It also checks the sign of the determinant for the faster check)
							<br>
							The benefit would be that some early exits could occur and never have to divide.
						</li>
						<li>
							Early exits:<br>
							If the determinant is zero, the ray is co-planar with the triangle.<br>
							If \(v\) is out of range.<br>
							If \(w\) or \(v+w\) are out of range.<br>
							If \(t\) is out of range.
						</li>
					</ul>
				</li>
			</ul>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part1/spheres.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part1/gems.png" width="400px"/>
							<figcaption><code>sky/CBgems.dae</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part1/coil.png" width="400px"/>
							<figcaption><code>sky/CBcoil.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part1/dragon.png" width="400px"/>
							<figcaption><code>sky/CBdragon.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 2: Bounding Volume Hierarchy</h2>
			<ul>
				<li>
					The splitting algorithm starts by iterating through the three base axes.
					<br>
					For each of the axis it finds the position of the median bounding box centroid of the primitives. Then it finds the surface area of each child volume and sums them.
					<br>
					The axis split that yields the best surface area is kept.
					<br>
					Using the median element is nice because it maintains a balanced tree. It, however, cannot account for some situations that could greatly reduce the surface area. (Like if the geometry is in two tightly packed differently sized regions)
				</li>
				<li>
					Traversal Optimization:<br>
					When traversing the acceleration structure, I tried to minimize unnecessary work. To do this, the algorithm always traverses the closer child node first.
					Then it does not traverse the other child node if the ray's hit point is closer than the external hit point of the child node.
				</li>
				<li>
					Performance difference:
					<ul>
						<li>
							<code>meshedit/cow.dae</code> at 1spp, res=380x560:<br>
							Render time: 3.0241s → 0.0173s (0.57%)<br>
							BVH generation time: 0.0060s<br>
						</li>
						<li>
							<code>meshedit/maxplanck.dae</code> at 1spp, res=380x560:<br>
							Render time: 25.3723s → 0.0231s (0.091%)<br>
							BVH generation time: 0.0760s<br>
						</li>
						<li>
							<code>sky/CBlucy.dae</code> at 1spp, res=380x560:<br>
							Render time: 84.5542s → 0.0157s (0.018%)<br>
							BVH generation time: 0.2362s<br>
						</li>
					</ul>
					This is quite a large speedup. Even when considering the generation time of the BVH. If the BVH had to be re-constructed every render, it would still be very worth while.
					<br>
					Going from least to most triangles, the performance improvement clearly increases. The cow took 0.57% of the original time while the angel took 0.018% of the time.
					This makes sense because the naive method increases linearly while the BVH traversal increases inverse exponentially.
				</li>
			</ul>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part2/lucy.png" width="400px"/>
							<figcaption><code>sky/CBlucy.dae</code> (64 spp)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part2/wall-e.png" width="400px"/>
							<figcaption><code>sky/wall-e.dae</code> (64 spp)</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part2/maxplanck.png" width="400px"/>
							<figcaption><code>meshedit/maxplanck.dae</code> (64 spp)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part2/bvh.png" width="400px"/>
							<figcaption>BVH visualization for <code>sky/wall-e.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 3: Direct Illumination</h2>
			<ul>
				<li>
					Both of the direct lighting functions start by getting relevant information about the intersection. (hit point, incoming direction, space conversion matrices).
					<br>
					Then they accumulate samples.
					<ul>
						<li>
							The uniform sampler samples by the number of lights times the number of samples per light.
							<br>
							For each, it gets a random direction from the surface. It converts it to world space and emits a ray in that direction.
							<br>
							If the ray hits something, it adds the BSDF times the emission of the object it hit and accumulates the result.
							<br>
							Then it divides the final accumulation by the number of samples and appropriate constant(s) (pdf=\(\frac{1}{2}\)).
						</li>
						<li>
							The importance sampler iterates through the lights. Point lights only get sampled once, while area lights get sampled according to the command line argument.
							<br>
							Then it accumulates (for each sample that hit) the BSDF times the radiance over the pdf.
							<br>
							The accumulation for each light is divided by the number of samples spent on that light, then added to a larger accumulator.
							<br>
							Then the final accumulation of all lights is divided by appropriate constant(s) (\(\pi\)).
						</li>
					</ul>
				</li>
				<li>
					Optimization:<br>
					To save some (very small) amount of work, I delayed dividing by the probability density function until the end (when it was constant).<br>
					I'm not sure if the compiler would have optimized this on its own because it has slightly different behavior (due to finite precision).
				</li>
				<li>
					The importance sampling improves results greatly. The uniformly sampled images are extremely noisy everywhere while the importance sampled images are primarily just noisy in partially shadowed areas.
					<br>
					This follows intuitive expectation because the chance that a uniform sample hits a light is low, but when it does hit, the effect is high.
				</li>
				<li>
					It appears that the effect of more samples (when importance sampling) diminishes. The difference between 1 sample and 4 samples appears larger than the difference between 16 samples and 64 samples.
					This (most likely) means that it is converging because as it converges, the effect of refinement becomes less and less.
				</li>
			</ul>

			<p>Comparison of uniform hemisphere sampling (left) and importance sampling (right) at 32 light samples:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_unif.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>uniform</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/bunny_unif.png" width="400px"/>
							<figcaption><code>sky/CBbunny.dae</code><br>uniform</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/bunny_imp.png" width="400px"/>
							<figcaption><code>sky/CBbunny.dae</code><br>importance</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Importance sampling at different light sample rates:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_1x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 1 light sample</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_4x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 4 light samples</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_16x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 16 light samples</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part3/spheres_imp_64x.png" width="400px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code><br>importance 64 light samples</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 4: Global Illumination</h2>
			<ul>
				<li>
					My implementation of the lighting function was a little different than the recursive description given in class. I unrolled the recursion and accumulated values.
					<br>
					\(R_n\) being the one bounce radiance:
					\[L_1 = R_1 + \frac{f_1}{p_1}L_2, L_n = R_n + \frac{f_n}{p_n}L_{n+1}\]
					\[L_1 = R_1 + \frac{f_1}{p_1}\left( R_2 + \frac{f_2}{p_2}\left( R_3 + \frac{f_3}{p_3}\left( R_4 + \frac{f_4}{p_4}\left( R_5 + \frac{f_5}{p_5}\left( \cdots \right) \right) \right) \right) \right)\]
					Because the recursive algorithm always terminates in a finite amount of time (\(\exists N, L_N:=0\)):
					\[L_1 = R_1 + \sum_{n=1}^{N}{ R_{i+1} \prod_{i=1}^{n-1} { \frac{f_i}{p_i} } }\]
					So now this can be written in a for loop that accumulates \(f\) and \(p\). Because \(f\) is a vector and \(p\) is a scalar, it made sense to have two different variables for accumulating them.
					<br>
					The final for loop does the following:<br>
					<ul>
						<li>Check for intersection, if miss, break.</li>
						<li>Add zero bounce radiance if this is the first ray.</li>
						<li>Calculate space conversion matrices.</li>
						<li>Add the product of the one bounce radiance and the accumulated values to the total light value.</li>
						<li>Create the next ray based on a new BSDF sample.</li>
						<li>Accumulate \(f\) and \(p\) (<code>pdf</code>) from the new BSDF sample.</li>
					</ul>
					<br>
					This method was chosen to reduce stack allocations and memory usage. The memory usage is constant with path depth. This optimization is likely necessary when implementing this on graphics hardware.
				</li>
			</ul>

			<p>Global illumination for a few scenes:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/global/spheres.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/global/dragon.png" width="370px"/>
							<figcaption><code>sky/dragon.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/global/bench.png" width="370px"/>
							<figcaption><code>sky/bench.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			In the following scene, the lighting is able to reach most of the model, so the effect of indirect illumination is fairly subtle.
			Looking at the indirect illumination only, the model appears to be lit from below. This makes sense because the light is going from above, reflecting off the upwards facing surfaces and hitting the downwards facing surfaces.
			<p>Comparison of only direct and only indirect illumination for <code>sky/wall-e.dae</code>:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/full.png" width="370px"/>
							<figcaption>global (sum)</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/direct.png" width="370px"/>
							<figcaption>direct only</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/dir_vs_indir/indirect.png" width="370px"/>
							<figcaption>indirect only</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<br>
			For the following image comparison:<br>
			The second and third bounces appear to get almost of the indirect lighting in this scene. The second bounce seems to capture all of the light reflected directly off of the floor.
			This is a fairly large effect because the light is facing the floor (so a lot of energy is going there).
			The second bounce also shows how the colors of the walls appear on the floor and ceiling.
			The third bounce appears to be adding some of the same effects but attenuated.
			Both are also adding light in areas that have a large open/visible surface area which ends up creating the effect of ambient occlusion.
			Rasterization rendering would usually create the ambient and ambient occlusion lighting in a very limited and approximate way. It would not create the color bleeding at all.

			<p>Global illumination breakdown for <code>sky/CBbunny.dae</code>:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_0.png" width="190px"/>
							<figcaption>0 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_1.png" width="190px"/>
							<figcaption>1 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_2.png" width="190px"/>
							<figcaption>2 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_3.png" width="190px"/>
							<figcaption>3 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_4.png" width="190px"/>
							<figcaption>4 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_ind_5.png" width="190px"/>
							<figcaption>5 Bounce</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_0.png" width="190px"/>
							<figcaption>0 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_1.png" width="190px"/>
							<figcaption>1 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_2.png" width="190px"/>
							<figcaption>2 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_3.png" width="190px"/>
							<figcaption>3 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_4.png" width="190px"/>
							<figcaption>4 Bounce</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/ind_comp/part4_sum_5.png" width="190px"/>
							<figcaption>5 Bounce</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Comparison of different maximum ray depths for <code>sky/CBbunny.dae</code> (Russian Roulette factor 0.3):</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/depth/0.png" width="370px"/>
							<figcaption>0</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/1.png" width="370px"/>
							<figcaption>1</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/2.png" width="370px"/>
							<figcaption>2</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/depth/3.png" width="370px"/>
							<figcaption>3</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/4.png" width="370px"/>
							<figcaption>4</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/depth/100.png" width="370px"/>
							<figcaption>100</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Comparison of different sample per pixel rates for <code>sky/CBspheres_lambertian.dae</code> (at 4 light samples):</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/1.png" width="280px"/>
							<figcaption>1</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/2.png" width="280px"/>
							<figcaption>2</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/4.png" width="280px"/>
							<figcaption>4</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/8.png" width="280px"/>
							<figcaption>8</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/16.png" width="280px"/>
							<figcaption>16</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/32.png" width="280px"/>
							<figcaption>32</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/64.png" width="280px"/>
							<figcaption>64</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part4/sample_rate/1024.png" width="280px"/>
							<figcaption>1024</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 5: Adaptive Sampling</h2>
			<ul>
				<li>
					To implement the adaptive sampling, I just modified the existing loop to check a condition every <code>samplesPerBatch</code> iterations.
					<br>
					Every iteration also sums the illumination and square of the illumination.
					<br>
					Then every <code>samplesPerBatch</code> samples, it calculates \(I\) and \(\mu\) to determine if the pixel has converged. If the pixel converged, it breaks out of the loop.
					<br>
					The only issue was that in some lighting conditions, some samples would converge too early. This primarily only happened to indirect lighting.
					To fix this, I only start checking the convergence of samples after <code>4*samplesPerBatch</code> samples. This way there is a greatly reduced chance of a pixel only sampling too many zeros and returning early.
				</li>
			</ul>

			<p>Adaptive sampling:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/part5/spheres.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part5/spheres_rate.png" width="370px"/>
							<figcaption><code>sky/CBspheres_lambertian.dae</code></figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="images/part5/wall-e.png" width="370px"/>
							<figcaption><code>sky/wall-e.dae</code></figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/part5/wall-e_rate.png" width="370px"/>
							<figcaption><code>sky/wall-e.dae</code></figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
			<h3>GPU Compute</h3>
			<h4>Restructuring:</h4>

			In order to implement this, I started by restructuring some code to allow for picking the GPU or CPU to do rendering.<br>
			I made a new class, <code>GPUPathTracer</code>, which renders one tile at a time using the GPU.<br>
			I made another new class, <code>GPU_BVHAccel</code>, which is a version of the BVH that it optimized for sending to and using on the GPU.<br>
			Because (atleast the last I heard) OpenGL does not support multithreading, I completely disable any thread spawning when GPU compute is selected.

			<h4>Ray Generation:</h4>

			To compute rays from the camera, I opted to use a matrix. This was because the entire view transformation could be done with two mutliplications using this matrix. (and 6 divisions, 3 subtractions, and a vector normalization to get the final ray).
			<br>
			The goal is for ray perspective generation and the camera transformation to be done simultaneously.
			<br>
			The final matrix looked like this (should look similar to the inverse of the standard perspective matrix):
			\[
			M=\begin{bmatrix}
			\frac{2}{\text{width}}\cdot\tan\left(\frac{f_h}{2}\right) && 0 && 0 && -\tan\left(\frac{f_h}{2}\right)\\
			0 && \frac{2}{\text{height}}\cdot\tan\left(\frac{f_v}{2}\right) && 0 && -\tan\left(\frac{f_v}{2}\right)\\
			0 && 0 && 0 && -1\\
			0 && 0 && -\frac{\text{far}-\text{near}}{\text{far}\cdot\text{near}} && \frac{\text{far}}{\text{far}\cdot\text{near}}
			\end{bmatrix}
			\]
			Taking the vectors,
			\[
			\alpha=\begin{bmatrix}
			x\\y\\0\\1
			\end{bmatrix}
			,
			\beta=\begin{bmatrix}
			x\\y\\1\\1
			\end{bmatrix}
			\]
			and computing,
			\[
			a=\frac{(M\alpha)_{xyz}}{(M\alpha)_w}, b=\frac{(M\beta)_{xyz}}{(M\beta)_w}
			\]
			yields the ray origin and direction,
			\[
			r_o = a\\
			r_d = \text{normalize}(b-a)
			\]
			What this is doing is finding coordinates on the near and far planes. The origin is set to the coordinate on the near plane, and the direction is the difference between the point on the near and far planes.
			<br>
			Consequently, the ray starts at the near plane rather than the pinhole camera's origin. This means that the ray's minimum \(t\) should be set to zero for the camera ray.
			<br>
			The benifit is that this matrix can be combined with the camera view matrix, and the latter computation can be done afterwards. (leaving just one 4x4 matrix being sent to the GPU program)
			<br>
			This also takes the pixel location in directly (rather than having to scale to \([0,1]\)coordinates first).
			<br>
			Testing:
			<br>
			<p>Testing the ray origin:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_x.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera to the right.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_y.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera up.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/origin_z.png" width="370px"/>
							<figcaption>The ray origin for each pixel after translating the camera back.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<p>Testing the ray direction:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/ray_dir_test.png" width="370px"/>
							<figcaption>The direction of the ray for each pixel after rotating the camera slightly up and to the right.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			Actual triangle intersections will be much more conclusive as to whether this is working propertly or not. If the scene aligns perfectly, then it is likely correct.

			<h4>Triangle Intersection:</h4>

			I used an OpenGL storage buffer to send the data for each triangle.<br>
			I translated the earlier implementation of the Möller Trumbore algorithm in GLSL.<br>
			<br>
			A compute shader does the actual computation using a for loop to go through each triangle.

			<p>Testing the ray generation and triangle intersection:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/normal_shading.png" width="370px"/>
							<figcaption><code>sky/CBempty.dae</code> with raw absolute value normal shading.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="images/gpu/initial/bunny_normal.png" width="370px"/>
							<figcaption><code>sky/CBbunny.dae</code> with raw absolute value normal shading.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			The bunny only took 8.3613 seconds with no acceleration structure, so despite having to check a huge number of triangle intersections, it is quite fast.
			<br>
			Also, these results show that the ray generation from the previous part is working. The position of the faces do not change at all when rendering.

			<p>Testing the near clipping plane with the ray generation:</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="images/gpu/initial/near_clipping.png" width="370px"/>
							<figcaption><code>sky/CBempty.dae</code> very close to camera</figcaption>
						</td>
					</tr>
				</table>
			</div>

			The clipping effect in this image aligned with the clipping done by the rasterized preview, so it is likely correct.

			<h4>Acceleration Structure Construction, Storage, and Traversal:</h4>

			<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
		</div>
	</body>
</html>
